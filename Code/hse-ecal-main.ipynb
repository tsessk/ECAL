{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lmfit","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:40.490068Z","iopub.execute_input":"2023-05-18T14:00:40.491061Z","iopub.status.idle":"2023-05-18T14:00:54.984625Z","shell.execute_reply.started":"2023-05-18T14:00:40.491013Z","shell.execute_reply":"2023-05-18T14:00:54.983305Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lmfit in /opt/conda/lib/python3.7/site-packages (1.2.1)\nRequirement already satisfied: asteval>=0.9.28 in /opt/conda/lib/python3.7/site-packages (from lmfit) (0.9.29)\nRequirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from lmfit) (1.21.6)\nRequirement already satisfied: scipy>=1.6 in /opt/conda/lib/python3.7/site-packages (from lmfit) (1.7.3)\nRequirement already satisfied: uncertainties>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from lmfit) (3.1.7)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from asteval>=0.9.28->lmfit) (4.11.4)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from uncertainties>=3.1.4->lmfit) (0.18.3)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->asteval>=0.9.28->lmfit) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->asteval>=0.9.28->lmfit) (3.11.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport optuna\nimport wandb\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.ndimage.measurements import center_of_mass\nfrom torch.optim import SGD\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\nfrom lmfit.models import GaussianModel\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:54.987286Z","iopub.execute_input":"2023-05-18T14:00:54.987740Z","iopub.status.idle":"2023-05-18T14:00:55.012164Z","shell.execute_reply.started":"2023-05-18T14:00:54.987699Z","shell.execute_reply":"2023-05-18T14:00:55.010843Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = '9c87219b80917d112c22c20a605d8dc6d6befdfd'","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.014085Z","iopub.execute_input":"2023-05-18T14:00:55.014514Z","iopub.status.idle":"2023-05-18T14:00:55.023264Z","shell.execute_reply.started":"2023-05-18T14:00:55.014472Z","shell.execute_reply":"2023-05-18T14:00:55.021374Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_time_cell_3x3(row):\n    time = row[:9]\n    energy = row[9:]\n    return (time * energy).sum() / (energy.sum() + 1e-6)\n\n\ndef get_time_cell_5x5(row):\n    time = row[:25]\n    energy = row[25:]\n    return (time * energy).sum() / (energy.sum() + 1e-6)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.027666Z","iopub.execute_input":"2023-05-18T14:00:55.028169Z","iopub.status.idle":"2023-05-18T14:00:55.038566Z","shell.execute_reply.started":"2023-05-18T14:00:55.028093Z","shell.execute_reply":"2023-05-18T14:00:55.037177Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_new_feats_and_train_feats(df, layers=[0], conv_check=False):\n    df['t_ECAL'] = df.timing.values\n\n    for layer in layers:\n        df['t{}_weighted_3x3'.format(layer)] = np.apply_along_axis(get_time_cell_3x3, \n                                                    axis=1, \n                                                    arr=df[['t{}_{}'.format(layer,c) for c in [6,7,8,11,12,13,16,17,18]] + \\\n                                                           ['l{}_{}'.format(layer,c) for c in [6,7,8,11,12,13,16,17,18]]].values)\n\n        df['t{}_weighted_5x5'.format(layer)] = np.apply_along_axis(get_time_cell_5x5, \n                                                    axis=1, \n                                                    arr=df[['t{}_{}'.format(layer,c) for c in range(25)] + \\\n                                                           ['l{}_{}'.format(layer,c) for c in range(25)]].values)\n\n\n    for layer in layers:\n        df['l{}_sum_3x3'.format(layer)] = \\\n            df[['l{}_{}'.format(layer, i) for i in [6,7,8,\n                                                    11,12,13,\n                                                    16,17,18]]].values.sum(axis=1)\n\n        df['l{}_sum_5x5'.format(layer)] = \\\n            df[['l{}_{}'.format(layer, i) for i in range(25)]].values.sum(axis=1)\n        \n    train_features = []\n    \n    if not conv_check:\n        train_features += ['t0_{}'.format(i) for i in range(25)] + \\\n                          ['t0_weighted_3x3','t0_weighted_5x5']\n    \n    for layer in layers:\n            train_features += ['l{}_{}'.format(layer, i) for i in range(25)]\n            if not conv_check:\n                train_features += ['l{}_sum_3x3'.format(layer)] + \\\n                ['l{}_sum_5x5'.format(layer)]\n    \n    return df, train_features","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.040626Z","iopub.execute_input":"2023-05-18T14:00:55.041239Z","iopub.status.idle":"2023-05-18T14:00:55.062129Z","shell.execute_reply.started":"2023-05-18T14:00:55.041179Z","shell.execute_reply":"2023-05-18T14:00:55.060673Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, X_, y_):\n        self.X = torch.tensor(X_.values,dtype=torch.float32)\n        self.y = torch.tensor(y_.values,dtype=torch.float32)\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, index):\n        return self.X[index],self.y[index]\n\nclass MyConvDataset1Layer(Dataset):\n    def __init__(self, X_, y_):\n        super(Dataset, self).__init__()\n        self.X = torch.tensor(X_.values,dtype=torch.float32)\n        self.y = torch.tensor(y_.values,dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, index):\n        return self.X[index].reshape((5, 5)).unsqueeze(0), self.y[index]\n\nclass MyConvDataset2Layer(Dataset):\n    def __init__(self, X_, y_):\n        super(Dataset, self).__init__()\n        self.X = torch.tensor(X_.values,dtype=torch.float32)\n        self.y = torch.tensor(y_.values,dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, index):\n        return self.X[index].reshape((5, 10)).unsqueeze(0), self.y[index]","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.063971Z","iopub.execute_input":"2023-05-18T14:00:55.064399Z","iopub.status.idle":"2023-05-18T14:00:55.082589Z","shell.execute_reply.started":"2023-05-18T14:00:55.064359Z","shell.execute_reply":"2023-05-18T14:00:55.081222Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_and_validate(model, optimizer, criterion, metric, train_loader, val_loader,\n                       num_epochs, device, scheduler=None, verbose=True):\n    \n    prev_met = 10e3\n\n\n    for epoch in range(1, num_epochs + 1):\n        model.train()\n        running_loss, running_metric = 0, 0\n        \n        pbar = tqdm(train_loader, desc=f'Training {epoch}/{num_epochs}') \\\n            if verbose else train_loader\n\n        for X_batch, y_batch in pbar:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            optimizer.zero_grad()\n            predictions = model(X_batch)\n            y_batch = y_batch.unsqueeze(1)\n            loss = criterion(predictions, y_batch)\n            loss.backward()\n            optimizer.step()\n            \n            if scheduler is not None:\n                scheduler.step()\n\n            metric_value = metric(np.nan_to_num(predictions.cpu().detach().numpy()), np.nan_to_num(y_batch.cpu().detach().numpy()))\n            running_loss += loss.item() * X_batch.shape[0]\n            running_metric += metric_value * X_batch.shape[0]\n            if verbose:\n                pbar.set_postfix({'loss': loss, 'MSE': metric_value})\n        \n\n        train_loss = running_loss / len(train_loader.dataset)\n        train_metric = running_metric / len(train_loader.dataset)\n\n        model.eval()\n        running_loss, running_metric = 0, 0\n        pbar = tqdm(val_loader, desc=f'Validating {epoch}/{num_epochs}') \\\n            if verbose else val_loader\n\n        for X_batch, y_batch in pbar:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            \n            predictions = model(X_batch)\n            y_batch = y_batch.unsqueeze(1)\n            loss = criterion(predictions, y_batch)\n            \n            metric_value =  metric(np.nan_to_num(predictions.cpu().detach().numpy()), np.nan_to_num(y_batch.cpu().detach().numpy()))\n            running_loss += loss.item() * X_batch.shape[0]\n            running_metric += metric_value * X_batch.shape[0]\n            if verbose:\n                pbar.set_postfix({'loss': loss, 'MSE': metric_value})\n\n        val_loss = running_loss / len(val_loader.dataset)\n        val_metric = running_metric / len(val_loader.dataset)\n        \n        if val_metric < prev_met:\n            print('better metric =', val_metric)\n            prev_met = val_metric\n\n        wandb.log({'train_loss': train_loss,\n                    'val_loss':  val_loss,\n                    'train_metric': train_metric,\n                   'val_metric': val_metric})\n        \n        \n\n    print(f'Validation MSE: {val_metric:.3f}')\n    \n    return train_metric, val_metric","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.084302Z","iopub.execute_input":"2023-05-18T14:00:55.084698Z","iopub.status.idle":"2023-05-18T14:00:55.107845Z","shell.execute_reply.started":"2023-05-18T14:00:55.084657Z","shell.execute_reply":"2023-05-18T14:00:55.106815Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_rmse(x, y):\n    return np.nanmean(((x - y) ** 2.0)) ** 0.5\n\ndef get_rmse_metric(x, y, folds=5):\n    if x.shape != y.shape:\n        print('x.shape != y.shape')\n        raise\n\n    splits = np.array_split(np.arange(len(x)), folds)\n\n    rmse = []\n    for split in splits:\n        rmse.append(get_rmse(x[split], y[split]))\n\n    return np.nanmean(rmse), np.nanstd(rmse)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.109664Z","iopub.execute_input":"2023-05-18T14:00:55.110581Z","iopub.status.idle":"2023-05-18T14:00:55.125537Z","shell.execute_reply.started":"2023-05-18T14:00:55.110533Z","shell.execute_reply":"2023-05-18T14:00:55.124204Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def extract_timing_resolution(df, save=True, title=None):\n    cell_size = 1.515\n    mod = GaussianModel()\n    E_bins = [10000., 30000., 50000., 70000., 90000.]\n\n    sel = (df.cell_size == cell_size)\n    df = df[sel & (df.p_ECAL > E_bins[0]) & (df.p_ECAL < E_bins[-1])].reset_index(drop=True)\n    target = df.t_pred\n    n_stds = 5\n\n    range_all = (-n_stds*np.std(target - df.t_ECAL), n_stds*np.std(target - df.t_ECAL))\n\n    fig, ax = plt.subplots(1, len(E_bins)-1, figsize=(20,3))\n    bins_plotting = (np.array(E_bins[:-1]) + np.array(E_bins[1:])) / 2.0\n    sigmas = []\n    sigmas_std = []\n\n    for i in [0, 1, 2, 3]:\n        mask = (df.p_ECAL >= E_bins[i]) & (df.p_ECAL < E_bins[i+1])\n        bin_heights, bin_borders, _ = ax[i].hist(target[mask]/df.t_ECAL[mask] - 1, bins=30, \\\n             range=(-n_stds*np.std(target[mask]/df.t_ECAL[mask] - 1), n_stds*np.std(target[mask]/df.t_ECAL[mask] - 1)), color='C02')\n        bin_centers = (bin_borders[:-1] + bin_borders[1:]) / 2.0\n        pars = mod.guess(bin_heights, x = bin_centers)\n        out = mod.fit(bin_heights, pars, x = bin_centers)\n        x = np.linspace(bin_borders[0], bin_borders[-1], 200)\n        ax[i].plot(bin_centers, out.best_fit, label='best fit', color='C03')\n        ax[i].set_title(f'Bin {i} ({0.001*E_bins[i]}-{0.001*E_bins[i+1]} GeV, {len(df.p_ECAL[mask])} entries)')\n        ax[i].set_xlabel(r'$t_{rec} - t_{gen}$ [ns]', fontsize=14)\n\n        \n        sigmas.append(out.params['sigma'].value)\n        sigmas_std.append(out.params['sigma'].stderr)\n    \n    if title is not None:\n        plt.title(title)\n    if save:\n        plt.savefig(f'plot_hist_{title}.png', dpi=300, bbox_inches='tight')\n    plt.close()\n        \n    return sigmas, sigmas_std","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.127664Z","iopub.execute_input":"2023-05-18T14:00:55.128471Z","iopub.status.idle":"2023-05-18T14:00:55.151746Z","shell.execute_reply.started":"2023-05-18T14:00:55.128426Z","shell.execute_reply":"2023-05-18T14:00:55.150224Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def plot_rec_curve(sigmas, sigmas_std, save=True, title=None):\n    fig, ax = plt.subplots(figsize=(10,10))\n\n    x = [20, 40, 60, 80]\n\n    x_ref = [2., 3., 4., 5., 20., 30., 50., 70., 100.]\n    y_ref1 = [44.71,34.90,29.48,26.19,19.39,17.40,15.35,14.04,13.63]\n    y_ref2 = [56.99,47.04,41.35,37.89,26.15,22.83,16.34,13.36,12.36]\n    \n    if len(sigmas) == 0 or len(sigmas_std) == 0 or None in sigmas or None in sigmas_std:\n        return\n    \n    y_b = [i*100000 for i in sigmas]\n    yerr_b = [i*100000 for i in sigmas_std]\n\n    ax.set_xlabel(r'$E_{gen}$ [GeV]', fontsize=18)\n    ax.set_ylabel('Time resolution [ps]', fontsize=18)\n\n    \n    ax.grid(True, which=\"both\")\n\n    ax.errorbar(x, y_b, yerr=yerr_b, fmt='o', c='C03', alpha=0.7, label='Current reconstruction')\n    ax.plot(x_ref, y_ref1, 'g--', label=\"Reference 1\")\n    ax.plot(x_ref, y_ref2, 'b--', label=\"Reference 2\")\n    ax.legend(fontsize=16, loc='upper right')\n    \n    if title is not None:\n        plt.title(title)\n    \n    if save:\n        plt.savefig(f'plot_rec_{title}.png', dpi=300, bbox_inches='tight')\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:55.156864Z","iopub.execute_input":"2023-05-18T14:00:55.157337Z","iopub.status.idle":"2023-05-18T14:00:55.173852Z","shell.execute_reply.started":"2023-05-18T14:00:55.157295Z","shell.execute_reply":"2023-05-18T14:00:55.172395Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df aggregate= pd.read_csv('../input/ecal-complex/1ph_2L.csv')\n#df = pd.read_csv('../input/hse-ecal/converted_all.csv')\ndf, tr_feats = get_new_feats_and_train_feats(df, [0, 1], True)\ndf = df.fillna(df.mean())\ndf['p_ECAL'] = df['eKinetic'].values * 1000\ndf['t_pred'] = 0\n\nX = df[tr_feats]\nX = (X - X.mean()) / X.std()\n\nX['p_ECAL'] = df['p_ECAL']\nX['cell_size'] = df[['cell_size']]\nX['t_ECAL'] = df['t_ECAL']\n\ny = X['t_ECAL']","metadata":{"execution":{"iopub.status.busy":"2023-05-18T14:00:26.269568Z","iopub.execute_input":"2023-05-18T14:00:26.270013Z","iopub.status.idle":"2023-05-18T14:00:29.997830Z","shell.execute_reply.started":"2023-05-18T14:00:26.269974Z","shell.execute_reply":"2023-05-18T14:00:29.993770Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1600361494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/ecal-complex/1ph_2L.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#df = pd.read_csv('../input/hse-ecal/converted_all.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_new_feats_and_train_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p_ECAL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eKinetic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'get_new_feats_and_train_feats' is not defined"],"ename":"NameError","evalue":"name 'get_new_feats_and_train_feats' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=812)\nX_train = X_train[tr_feats]\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=812)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T09:59:46.071282Z","iopub.execute_input":"2023-05-18T09:59:46.071972Z","iopub.status.idle":"2023-05-18T09:59:47.826728Z","shell.execute_reply.started":"2023-05-18T09:59:46.071929Z","shell.execute_reply":"2023-05-18T09:59:47.825628Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"TrainSet = MyDataset(X_train, y_train)\nValSet = MyDataset(X_val, y_val)\nTestSet = MyDataset(X_test[tr_feats], y_test)\n\nTrainLoader = DataLoader(TrainSet, batch_size=1024, pin_memory=True, num_workers=2)\nValLoader = DataLoader(ValSet, batch_size=1024, pin_memory=True, num_workers=2)\nTestLoader = DataLoader(TestSet, shuffle=False, pin_memory=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:02:41.352069Z","iopub.execute_input":"2023-05-18T10:02:41.352847Z","iopub.status.idle":"2023-05-18T10:02:41.647752Z","shell.execute_reply.started":"2023-05-18T10:02:41.352803Z","shell.execute_reply":"2023-05-18T10:02:41.646627Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class ConvNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=2, padding='same')\n        self.bn = nn.BatchNorm2d(32)\n\n        self.head = nn.Linear(32 * 8 * 8, 128)\n    def forward(self, x):\n        out = self.conv(x)\n        out = self.bn(out)\n\n        out = self.head(out)\n        return out.reshape((128, -1))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:33:39.486378Z","iopub.execute_input":"2023-05-18T01:33:39.486931Z","iopub.status.idle":"2023-05-18T01:33:39.498979Z","shell.execute_reply.started":"2023-05-18T01:33:39.486886Z","shell.execute_reply":"2023-05-18T01:33:39.497355Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"N_EPOCH = 30\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nnet = ConvNet()\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCH * len(TrainLoader))\n\n\nmetric_rmse = lambda a, b: mean_squared_error(a, b, squared=False)\n\n\n\ntrain_and_validate(net, optimizer, criterion, metric_rmse, TrainLoader, ValLoader, N_EPOCH, device, scheduler, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T13:59:58.970852Z","iopub.execute_input":"2023-05-18T13:59:58.971892Z","iopub.status.idle":"2023-05-18T13:59:58.996981Z","shell.execute_reply.started":"2023-05-18T13:59:58.971844Z","shell.execute_reply":"2023-05-18T13:59:58.995670Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.layers = nn.ModuleList(\n            [\n                self.build_block(len(tr_feats), 128),\n                self.build_block(128, 256),\n                self.build_block(256, 128),\n                self.build_block(128, 64)\n            ]\n        )\n        \n        self.skip_connections = nn.ModuleList(\n            [\n                nn.AdaptiveAvgPool1d(128),\n                nn.AdaptiveAvgPool1d(256),\n                nn.AdaptiveAvgPool1d(128),\n                nn.AdaptiveAvgPool1d(64)\n            ]\n        )\n        self.head = nn.Linear(64, 1)\n        \n    def build_block(self, in_feats, out_feats):\n        return  nn.Sequential(\n                    nn.Linear(in_feats, out_feats),\n                    nn.BatchNorm1d(out_feats),\n                    nn.ReLU())\n        \n        \n    def forward(self, x):\n        out = x\n\n        for i in range(len(self.layers)):\n            out = self.skip_connections[i](out) + self.layers[i](out)\n            \n        out = self.head(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:27:57.550007Z","iopub.execute_input":"2023-05-18T01:27:57.551091Z","iopub.status.idle":"2023-05-18T01:27:57.563813Z","shell.execute_reply.started":"2023-05-18T01:27:57.551017Z","shell.execute_reply":"2023-05-18T01:27:57.562746Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 25\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nbest_model = None\nbest_metric = 1e3\n\n    \ndef train_and_evaluate(model, params, trial):\n    \n    TrainLoader = DataLoader(TrainSet, batch_size=params['batch_size'], pin_memory=True, num_workers=2)\n    ValLoader = DataLoader(ValSet, batch_size=params['batch_size'], pin_memory=True, num_workers=2)\n    \n    criterion = nn.MSELoss()\n    metric = lambda a, b: mean_squared_error(a, b, squared=False)\n    optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS * len(TrainLoader))\n\n    \n    if torch.cuda.is_available():\n        criterion = criterion.cuda()\n        model = model.cuda()\n    \n    print(next(model.parameters()).device)\n    \n    for epoch in tqdm(range(NUM_EPOCHS)):\n        model.train()\n        running_loss, running_metric = 0, 0\n        \n        for X_batch, y_batch in TrainLoader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            \n            optimizer.zero_grad()\n            \n            predictions = model(X_batch)\n            y_batch = y_batch.unsqueeze(1)\n            loss = criterion(predictions, y_batch)\n            \n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            \n            metric_value = metric(np.nan_to_num(predictions.cpu().detach().numpy()), np.nan_to_num(y_batch.cpu().detach().numpy()))\n            running_loss += loss.item() * X_batch.shape[0]\n            running_metric += metric_value * X_batch.shape[0]\n            train_loss = running_loss / len(TrainLoader.dataset)\n            train_metric = running_metric / len(TrainLoader.dataset)\n            \n            \n        with torch.no_grad():\n            model.eval()\n            running_loss, running_metric = 0, 0\n            for X_batch, y_batch in ValLoader:\n\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n\n                predictions = model(X_batch)\n                y_batch = y_batch.unsqueeze(1)\n                loss = criterion(predictions, y_batch)\n                metric_value =  metric(np.nan_to_num(predictions.cpu().detach().numpy()), np.nan_to_num(y_batch.cpu().detach().numpy()))\n                running_loss += loss.item() * X_batch.shape[0]\n                running_metric += metric_value * X_batch.shape[0]\n                \n        val_loss = running_loss / len(ValLoader.dataset)\n        val_metric = running_metric / len(ValLoader.dataset)\n        \n        trial.report(val_metric, epoch)\n        \n        if trial.should_prune():\n                raise optuna.exceptions.TrialPruned()\n                \n    return val_metric\n\n    \n\ndef objective(trial):\n    params = {\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'batch_size': trial.suggest_categorical('batch_size', [1024, 2048, 4096])\n    }\n    \n    model = ResNet()\n    rmse = train_and_evaluate(model, params, trial)\n    print(trial.params)\n    \n    global best_model\n    global best_metric\n        \n    if rmse < best_metric:\n        best_metric = rmse\n        best_model = model\n        print('New best')\n\n    return rmse\n\nstudy = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=20)\n\nprint('BEST PARAMETERS:')\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T01:27:57.769850Z","iopub.execute_input":"2023-05-18T01:27:57.770890Z","iopub.status.idle":"2023-05-18T01:28:15.502400Z","shell.execute_reply.started":"2023-05-18T01:27:57.770834Z","shell.execute_reply":"2023-05-18T01:28:15.500431Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-05-18 01:27:57,796]\u001b[0m A new study created in memory with name: no-name-95436b2f-0f22-45ee-9332-5a5a1977300c\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"cpu\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/25 [00:17<?, ?it/s]\n\u001b[33m[W 2023-05-18 01:28:15,418]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 0.08823686721298425, 'batch_size': 64} because of the following error: KeyboardInterrupt().\u001b[0m\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_27/1280475857.py\", line 83, in objective\n    rmse = train_and_evaluate(model, params, trial)\n  File \"/tmp/ipykernel_27/1280475857.py\", line 38, in train_and_evaluate\n    loss.backward()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\", line 488, in backward\n    self, gradient, retain_graph, create_graph, inputs=inputs\n  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 199, in backward\n    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\nKeyboardInterrupt\n\u001b[33m[W 2023-05-18 01:28:15,423]\u001b[0m Trial 0 failed with value None.\u001b[0m\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1280475857.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BEST PARAMETERS:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         )\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1280475857.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1280475857.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, params, trial)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"N_EPOCH = 10\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nnet = ResBlock()\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCH * len(TrainLoader), verbose=True)\n\n\nmetric_rmse = lambda a, b: mean_squared_error(a, b, squared=False)\n\n\nrun_config = {\n    \"name\" : \"ResNet\",\n    \"learning_rate\": 1e-3,\n    \"epochs\": N_EPOCH\n}\n\nrun = wandb.init(project=\"HSE_ECAL_project\", config=run_config, name='ResNet Real')\n\ntrain_and_validate(net, optimizer, criterion, metric_rmse, TrainLoader, ValLoader, N_EPOCH, device, scheduler, verbose=True)\nrun.finish()\nbest_model = net","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:07:11.854417Z","iopub.execute_input":"2023-05-17T19:07:11.854927Z","iopub.status.idle":"2023-05-17T19:09:17.679131Z","shell.execute_reply.started":"2023-05-17T19:07:11.854885Z","shell.execute_reply":"2023-05-17T19:09:17.677406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS = 30\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nbest_model = None\nbest_metric = 1e3\n\ndef build_model(trial, params):\n    in_feats = len(tr_feats)\n    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n    layers = []\n    \n    for i in range(num_layers):\n        out_feats = trial.suggest_int('hidden_size_l{}'.format(i), 64, 256)\n        \n        layers.append(nn.Linear(in_features=in_feats, out_features=out_feats))\n        layers.append(nn.BatchNorm1d(out_feats))\n        layers.append(nn.ReLU())\n        layers.append(nn.Dropout(p=params['dropout_p']))\n        \n        in_feats = out_feats\n    \n    layers.append(nn.Linear(in_features=in_feats, out_features=32))\n    layers.append(nn.BatchNorm1d(32))\n    layers.append(nn.ReLU())\n    layers.append(nn.Linear(in_features=32, out_features=1))\n    \n    return nn.Sequential(*layers)\n        \n    \ndef train_and_evaluate(model, params, trial):\n    criterion = nn.MSELoss()\n    metric = lambda a, b: mean_squared_error(a, b, squared=False)\n    optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n    \n    if torch.cuda.is_available():\n        criterion = criterion.cuda()\n        model = model.cuda()\n    \n    print(next(model.parameters()).device)\n    \n    for epoch in tqdm(range(NUM_EPOCHS)):\n        model.train()\n        running_loss, running_metric = 0, 0\n        \n        for X_batch, y_batch in TrainLoader:\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n            \n            optimizer.zero_grad()\n            \n            predictions = model(X_batch)\n            y_batch = y_batch.unsqueeze(1)\n            loss = criterion(predictions, y_batch)\n            \n            loss.backward()\n            optimizer.step()\n            \n            metric_value = metric(np.nan_to_num(predictions.cpu().detach().numpy()), np.nan_to_num(y_batch.cpu().detach().numpy()))\n            running_loss += loss.item() * X_batch.shape[0]\n            running_metric += metric_value * X_batch.shape[0]\n            train_loss = running_loss / len(TrainLoader.dataset)\n            train_metric = running_metric / len(TrainLoader.dataset)\n            \n            \n        with torch.no_grad():\n            model.eval()\n            running_loss, running_metric = 0, 0\n            for X_batch, y_batch in ValLoader:\n\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n\n                predictions = model(X_batch)\n                y_batch = y_batch.unsqueeze(1)\n                loss = criterion(predictions, y_batch)\n                metric_value =  metric(np.nan_to_num(predictions.cpu().detach().numpy()), np.nan_to_num(y_batch.cpu().detach().numpy()))\n                running_loss += loss.item() * X_batch.shape[0]\n                running_metric += metric_value * X_batch.shape[0]\n                \n        val_loss = running_loss / len(ValLoader.dataset)\n        val_metric = running_metric / len(ValLoader.dataset)\n        \n        trial.report(val_metric, epoch)\n        \n        if trial.should_prune():\n                raise optuna.exceptions.TrialPruned()\n                \n    return val_metric\n\n    \n\ndef objective(trial):\n    params = {\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n        'dropout_p': trial.suggest_float('dropout_p', 0, 0.5)\n    }\n    \n    model = build_model(trial, params)\n    rmse = train_and_evaluate(model, params, trial)\n    print(trial.params)\n    \n    global best_model\n    global best_metric\n        \n    if rmse < best_metric:\n        best_metric = rmse\n        best_model = model\n        print('New best')\n\n    return rmse\n\nstudy = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=25)\nprint('BEST PARAMETERS:')\nprint(study.best_params)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T10:02:58.513904Z","iopub.execute_input":"2023-05-18T10:02:58.514384Z","iopub.status.idle":"2023-05-18T10:03:27.179526Z","shell.execute_reply.started":"2023-05-18T10:02:58.514325Z","shell.execute_reply":"2023-05-18T10:03:27.174892Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-05-18 10:02:58,540]\u001b[0m A new study created in memory with name: no-name-aa321c8c-7ace-4328-b82d-09699becadb3\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"cuda:0\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 2/40 [00:28<09:00, 14.24s/it]\n\u001b[33m[W 2023-05-18 10:03:27,030]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 0.060850635313584846, 'dropout_p': 0.18163681413396549, 'num_layers': 2, 'hidden_size_l0': 114, 'hidden_size_l1': 176} because of the following error: KeyboardInterrupt().\u001b[0m\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_23/3583032611.py\", line 98, in objective\n    rmse = train_and_evaluate(model, params, trial)\n  File \"/tmp/ipykernel_23/3583032611.py\", line 44, in train_and_evaluate\n    for X_batch, y_batch in TrainLoader:\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n    data = self._next_data()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1316, in _next_data\n    idx, data = self._get_data()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1272, in _get_data\n    success, data = self._try_get_data()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1120, in _try_get_data\n    data = self._data_queue.get(timeout=timeout)\n  File \"/opt/conda/lib/python3.7/queue.py\", line 179, in get\n    self.not_empty.wait(remaining)\n  File \"/opt/conda/lib/python3.7/threading.py\", line 300, in wait\n    gotit = waiter.acquire(True, timeout)\nKeyboardInterrupt\n\u001b[33m[W 2023-05-18 10:03:27,037]\u001b[0m Trial 0 failed with value None.\u001b[0m\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3583032611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BEST PARAMETERS:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         )\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3583032611.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3583032611.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, params, trial)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTrainLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"NUM_EPOCHS = 400\n\nmodel = nn.Sequential(\n    nn.Linear(in_features=len(tr_feats), out_features=256),\n    nn.BatchNorm1d(256),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(in_features=256, out_features=256),\n    nn.BatchNorm1d(256),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(in_features=256, out_features=256),\n    nn.BatchNorm1d(256),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(in_features=256, out_features=128),\n    nn.BatchNorm1d(128),\n    nn.ReLU(),\n    nn.Linear(in_features=128, out_features=1)\n)\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\ncriterion = nn.MSELoss()\nmodel = model.to(device)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=40, eta_min=1e-4)\n\nmetric_rmse = lambda a, b: mean_squared_error(a, b, squared=False)\n\nrun_config = {\n    \"learning_rate\": 1e-3,\n    \"epochs\": NUM_EPOCHS,\n    \"optimizer\": optimizer,\n    \"scheduler\": 'None'\n}\n\nrun = wandb.init(project=\"HSE_ECAL_project\", config=run_config)\n\ntrain_and_validate(model, optimizer, criterion, metric_rmse, TrainLoader, ValLoader, NUM_EPOCHS, device, scheduler, verbose=True)\nrun.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\n\nfor data, target in TestLoader:\n    data = data.to(device)\n    preds.append(best_model(data).item())\n\npreds = np.array(preds)\n\n\nmean_RMSE, std_RMSE = get_rmse_metric(y_test.values, preds)\nprint('mean_RMSE t_pred_NN: {:.5f}, std_RMSE: {:.5f}'.format(mean_RMSE, std_RMSE))\n\n\nrec_title = f'ResNet_optuna_best_P1'\nX_test['t_pred'] = preds\nsigmas, sigmas_std = extract_timing_resolution(X_test, save=True, title=rec_title)\nplot_rec_curve(sigmas, sigmas_std, save=True, title=rec_title)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T19:29:13.277496Z","iopub.execute_input":"2023-05-17T19:29:13.278116Z","iopub.status.idle":"2023-05-17T19:30:34.144725Z","shell.execute_reply.started":"2023-05-17T19:29:13.278051Z","shell.execute_reply":"2023-05-17T19:30:34.142963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}